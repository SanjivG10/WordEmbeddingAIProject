{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from collections import Counter\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets do some preprocessing! \n",
    "\n",
    "with open('nepali.txt','r',encoding=\"utf8\") as file:\n",
    "    texts = file.read()\n",
    "    sentences = texts.split('ред')\n",
    "    sentences = ' '.join(sentences)\n",
    "    # we separated by sentences, now we separate by words! \n",
    "    eachWords = sentences.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordsToGiveADamn = Counter(eachWords).most_common(1000)\n",
    "wordsToCheck = [w[0] for w in wordsToGiveADamn if not w[0] == '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordToIndex = {}\n",
    "IndexToWord = {}\n",
    "for index,word in enumerate(wordsToCheck):\n",
    "    wordToIndex[word] = index\n",
    "    IndexToWord[index] = word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordsWeAreProcessing =[]\n",
    "for eachWord in eachWords:\n",
    "    if wordToIndex.get(eachWord):\n",
    "        wordsWeAreProcessing.append(eachWord)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just the 8000 words! \n",
    "wordsWeAreProcessing = wordsWeAreProcessing[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing our set of words to vector\n",
    "wordsToVector = []\n",
    "for eachWord in wordsWeAreProcessing:\n",
    "    index= wordToIndex.get(eachWord)\n",
    "    zeroIndex =np.zeros(len(wordToIndex))\n",
    "    zeroIndex[index] = 1\n",
    "    wordsToVector.append(zeroIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiddenLayer():\n",
    "    def __init__(self,layer_number,activation_function='sigmoid'):\n",
    "        self.layer_number=layer_number\n",
    "        self.activation_function=activation_function\n",
    "\n",
    "class NeuralNetwork():\n",
    "    \n",
    "    def __init__(self,input_number,output_number):\n",
    "        self.raw_activations=[]\n",
    "        self.activations=[]\n",
    "        self.layers=[]\n",
    "        \n",
    "        self.input_number=input_number\n",
    "        self.output_number=output_number\n",
    "\n",
    "    def sigmoid(self,z,derivative=False):\n",
    "        if derivative:\n",
    "            return self.sigmoid(z)*(1-self.sigmoid(z))\n",
    "        return 1.0/(1.0+np.exp(-z))\n",
    "        \n",
    "    def add(self,layer):\n",
    "        self.layers.append(layer)\n",
    "        \n",
    "    def glorot_initializer(self,x,y):\n",
    "        r = np.sqrt((6/(x+y)))\n",
    "        value = np.random.uniform(-r,r,(x,y))\n",
    "        return value\n",
    "    \n",
    "    def weight_initializer(self,x,y):\n",
    "        return np.random.rand(x,y)\n",
    "        \n",
    "    def initialize(self):\n",
    "        layerNumbers=[]\n",
    "        layerNumbers.append(self.input_number)\n",
    "        \n",
    "        for eachLayer in self.layers:\n",
    "            layerNumbers.append(eachLayer.layer_number)\n",
    "        \n",
    "        layerNumbers.append(self.output_number)\n",
    "        \n",
    "        #so layerNumbers contains the input,hiddenLayers and output in a list! \n",
    "        # we initialize with glorot initialization! \n",
    "        \n",
    "        self.weights= [self.weight_initializer(x,y) for x,y in zip(layerNumbers[1:],layerNumbers[:-1])]\n",
    "        self.biases=[np.random.rand(x,1) for x in layerNumbers[1:]]\n",
    "        \n",
    "        \n",
    "    def feed_forward(self,a):\n",
    "        for w,b in zip(self.weights,self.biases):\n",
    "            a= np.dot(w,a)+b\n",
    "            z=self.sigmoid(a)\n",
    "        return z\n",
    "    \n",
    "    #works only for emvedding\n",
    "    def get_middle_layer(self,a):\n",
    "        for w,b in zip(self.weights,self.biases):\n",
    "            a= np.dot(w,a)+b\n",
    "            return a\n",
    "            \n",
    "    def backpropagate(self,x,y):\n",
    "        #we are at the last layer! \n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        \n",
    "        # okay feed_forwarding here!! \n",
    "        self.activations = []\n",
    "        self.raw_activations = []\n",
    "        \n",
    "        a=x\n",
    "        for w,b in zip(self.weights,self.biases):\n",
    "            a= np.dot(w,a)+b\n",
    "            self.raw_activations.append(a)\n",
    "            z=self.sigmoid(a)\n",
    "            self.activations.append(z)\n",
    "        \n",
    "        delta_val = self.activations[-1]-y\n",
    "                \n",
    "        delta = delta_val*self.sigmoid(self.raw_activations[-1],derivative=True)\n",
    "        #the first gradient from base and weight in final layer!!!\n",
    "        #delta should have same shape as that of activation!.. \n",
    "        # we would have same no of activations as weights! \n",
    "        nabla_b[-1] = delta\n",
    "        \n",
    "        nabla_w[-1] = np.dot(delta,self.activations[-2].T)\n",
    "        \n",
    "        # now we calculate nabla_b and nabla_w for other layers! \n",
    "        for j in range(len(self.weights)-2,0,-1):\n",
    "            sigmoid_value = self.sigmoid(self.raw_activations[j],derivative=True)\n",
    "            if j==1:\n",
    "                delta = np.dot(self.weights[j+1].T,delta)*sigmoid_value\n",
    "            else:\n",
    "                delta = np.dot(self.weights[j+1].T,delta)\n",
    "            nabla_b[j] = delta\n",
    "            nabla_w[j] = np.dot(delta,self.activations[j-1].T)\n",
    "        \n",
    "#         # activations doesnt contain input, so we do for this loop too! \n",
    "        sigmoid_value = self.sigmoid(self.raw_activations[0],derivative=True)\n",
    "        delta = np.dot(self.weights[1].T,delta)*sigmoid_value\n",
    "        \n",
    "        nabla_b[0] = delta\n",
    "        nabla_w[0] = np.dot(delta,x.T)\n",
    "        \n",
    "        return nabla_b,nabla_w\n",
    "        \n",
    "        \n",
    "        # why are we using Transpose here? Because delta is of shape 4*1 suppose and self.activations would also be 4.1\n",
    "        # so we use 4*1,1*4 to get 4*4 gradient! \n",
    "        #HURRAY THIS WORKS FOR BACKPROPAGATION FOR FINAL LAYER.. HOW ABOUT MOVING FROM IT NOW? \n",
    "#       return weight_gradient,bias_gradient\n",
    "    \n",
    "    def calculate_loss(self,calc_y,actual_y):\n",
    "        epsilon = 0.0000001\n",
    "        return -1*np.sum(actual_y*np.log(calc_y+epsilon) + (1-actual_y)*np.log(1-calc_y+epsilon))\n",
    "#         return 0.5*np.sum(np.square(calc_y-actual_y))\n",
    "\n",
    "    def test(self,x_actual,y_actual):\n",
    "        x = np.expand_dims(x_actual,axis=1)\n",
    "        y = np.expand_dims(y_actual,axis=1)\n",
    "        calculated_value = self.feed_forward(x)\n",
    "        print('Got this {}'.format(self.raw_activations[0]),end='\\n')\n",
    "        print('Loss => {}'.format(self.calculate_loss(calculated_value,y)))\n",
    "\n",
    "    def gradientDescent(self,batch_x,batch_y,epochs=100,learning_rate=0.1,verbose=False):\n",
    "        prev = 0.1*epochs\n",
    "        for i in range(epochs):\n",
    "            for x,y in zip(batch_x,batch_y):\n",
    "                \n",
    "                x=np.expand_dims(x,axis=1)\n",
    "                y=np.expand_dims(y,axis=1)\n",
    "                bias_gradient,weight_gradient = self.backpropagate(x,y)\n",
    "                self.biases  = [b-learning_rate*db for b,db in zip(self.biases,bias_gradient)]\n",
    "                self.weights = [w-learning_rate*dw for w,dw in zip(self.weights,weight_gradient)]\n",
    "                #testing the random data from the batch! \n",
    "            if verbose:\n",
    "                if i==int(prev):\n",
    "                    prev = prev + 0.1*epochs \n",
    "                    randomIndex= np.random.randint(0,len(batch_x)-1)\n",
    "                    self.test(batch_x[randomIndex],batch_y[randomIndex])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordsToVector=np.array(wordsToVector)\n",
    "X = wordsToVector[:len(wordsToVector)-1]\n",
    "Y = wordsToVector[1:len(wordsToVector)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZEOFINPUT = len(wordsToVector[0])\n",
    "SIZEOFOUTPUT = SIZEOFINPUT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNetwork(SIZEOFINPUT,SIZEOFOUTPUT)\n",
    "\n",
    "hiddenLayer1= HiddenLayer(20,'sigmoid')\n",
    "\n",
    "nn.add(hiddenLayer1)\n",
    "\n",
    "nn.initialize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got this [[-2.23669892]\n",
      " [-1.81662753]\n",
      " [-1.95328643]\n",
      " [-1.60976535]\n",
      " [-2.47841306]\n",
      " [ 2.35297227]\n",
      " [-1.87308565]\n",
      " [-2.45991199]\n",
      " [ 0.31080869]\n",
      " [-2.30422137]\n",
      " [-1.29575209]\n",
      " [ 1.58047893]\n",
      " [-1.04003999]\n",
      " [ 3.20166917]\n",
      " [ 2.42568128]\n",
      " [-0.73484694]\n",
      " [-2.33054594]\n",
      " [-0.1899229 ]\n",
      " [-1.47505882]\n",
      " [-0.11004645]]\n",
      "Loss => 8.769943817104043\n",
      "Got this [[-2.34822504]\n",
      " [-1.9221679 ]\n",
      " [-2.05207486]\n",
      " [-1.71851162]\n",
      " [-2.58417323]\n",
      " [ 2.46885174]\n",
      " [-1.98789092]\n",
      " [-2.5651895 ]\n",
      " [ 0.35509792]\n",
      " [-2.41121548]\n",
      " [-1.40025936]\n",
      " [ 1.69869754]\n",
      " [-1.13603708]\n",
      " [ 3.29738674]\n",
      " [ 2.54211726]\n",
      " [-0.82728301]\n",
      " [-2.43580027]\n",
      " [-0.25650163]\n",
      " [-1.58655545]\n",
      " [-0.1527111 ]]\n",
      "Loss => 7.641724449041483\n",
      "Got this [[-2.39531357]\n",
      " [-1.96642361]\n",
      " [-2.09374537]\n",
      " [-1.76779632]\n",
      " [-2.63247481]\n",
      " [ 2.52293329]\n",
      " [-2.03414689]\n",
      " [-2.6111073 ]\n",
      " [ 0.36781783]\n",
      " [-2.45644373]\n",
      " [-1.44786977]\n",
      " [ 1.75864858]\n",
      " [-1.18035763]\n",
      " [ 3.33448311]\n",
      " [ 2.59392922]\n",
      " [-0.87230848]\n",
      " [-2.48257396]\n",
      " [-0.29050324]\n",
      " [-1.63882197]\n",
      " [-0.17671303]]\n",
      "Loss => 6.853820223207752\n",
      "Got this [[-2.41864374]\n",
      " [-1.98453869]\n",
      " [-2.11041187]\n",
      " [-1.79947746]\n",
      " [-2.66825862]\n",
      " [ 2.57465697]\n",
      " [-2.04642083]\n",
      " [-2.63995591]\n",
      " [ 0.35611102]\n",
      " [-2.47696761]\n",
      " [-1.47538358]\n",
      " [ 1.82074572]\n",
      " [-1.21518211]\n",
      " [ 3.34537092]\n",
      " [ 2.63804505]\n",
      " [-0.89933447]\n",
      " [-2.51171561]\n",
      " [-0.29243315]\n",
      " [-1.67049449]\n",
      " [-0.20265121]]\n",
      "Loss => 11.210413828095797\n",
      "Got this [[-2.43585429]\n",
      " [-1.9975008 ]\n",
      " [-2.12298916]\n",
      " [-1.82352649]\n",
      " [-2.69333459]\n",
      " [ 2.61903338]\n",
      " [-2.05652478]\n",
      " [-2.66107417]\n",
      " [ 0.39378193]\n",
      " [-2.49462981]\n",
      " [-1.4868803 ]\n",
      " [ 1.88089971]\n",
      " [-1.21995174]\n",
      " [ 3.37475467]\n",
      " [ 2.69241154]\n",
      " [-0.89952293]\n",
      " [-2.53593906]\n",
      " [-0.28133626]\n",
      " [-1.68536528]\n",
      " [-0.19793607]]\n",
      "Loss => 8.216883581125707\n",
      "Got this [[-2.4549249 ]\n",
      " [-2.01271156]\n",
      " [-2.1391407 ]\n",
      " [-1.84767677]\n",
      " [-2.71499578]\n",
      " [ 2.64590339]\n",
      " [-2.06970647]\n",
      " [-2.68062368]\n",
      " [ 0.41366815]\n",
      " [-2.51435148]\n",
      " [-1.49981604]\n",
      " [ 1.9166012 ]\n",
      " [-1.22948958]\n",
      " [ 3.3918416 ]\n",
      " [ 2.72861062]\n",
      " [-0.91130642]\n",
      " [-2.55781325]\n",
      " [-0.28858039]\n",
      " [-1.70497598]\n",
      " [-0.204225  ]]\n",
      "Loss => 11.003668560862984\n",
      "Got this [[-2.47203832]\n",
      " [-2.02482342]\n",
      " [-2.15338772]\n",
      " [-1.86956457]\n",
      " [-2.73279713]\n",
      " [ 2.66870076]\n",
      " [-2.07796825]\n",
      " [-2.69698782]\n",
      " [ 0.42612586]\n",
      " [-2.53091981]\n",
      " [-1.5123916 ]\n",
      " [ 1.94681814]\n",
      " [-1.23983085]\n",
      " [ 3.40549027]\n",
      " [ 2.75339872]\n",
      " [-0.92383529]\n",
      " [-2.57642501]\n",
      " [-0.29528583]\n",
      " [-1.72360756]\n",
      " [-0.20876203]]\n",
      "Loss => 9.572898431965491\n",
      "Got this [[-2.4872632 ]\n",
      " [-2.03432388]\n",
      " [-2.16598607]\n",
      " [-1.89088944]\n",
      " [-2.74766353]\n",
      " [ 2.68881841]\n",
      " [-2.07992433]\n",
      " [-2.71089281]\n",
      " [ 0.43265351]\n",
      " [-2.54560701]\n",
      " [-1.525527  ]\n",
      " [ 1.97349809]\n",
      " [-1.25099856]\n",
      " [ 3.41683432]\n",
      " [ 2.7692389 ]\n",
      " [-0.93640444]\n",
      " [-2.59286347]\n",
      " [-0.30157466]\n",
      " [-1.74121481]\n",
      " [-0.21225884]]\n",
      "Loss => 8.579684387263553\n",
      "Got this [[-2.50107177]\n",
      " [-2.04089773]\n",
      " [-2.17729753]\n",
      " [-1.913753  ]\n",
      " [-2.76020037]\n",
      " [ 2.70698486]\n",
      " [-2.07179797]\n",
      " [-2.72288039]\n",
      " [ 0.43280373]\n",
      " [-2.55947638]\n",
      " [-1.53898109]\n",
      " [ 1.99682379]\n",
      " [-1.26229488]\n",
      " [ 3.42453642]\n",
      " [ 2.77691955]\n",
      " [-0.94947191]\n",
      " [-2.60821993]\n",
      " [-0.3082775 ]\n",
      " [-1.75833013]\n",
      " [-0.21619681]]\n",
      "Loss => 6.05998502784491\n"
     ]
    }
   ],
   "source": [
    "nn.gradientDescent(X,Y,100,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word embedding time! \n",
    "#how about saving words and their corresponding latent vectors? \n",
    "wordEmbeddingRelation = {}\n",
    "k=0\n",
    "for word in wordsToCheck:\n",
    "    index= wordToIndex.get(word)\n",
    "    zeroIndex =np.zeros(len(wordToIndex))\n",
    "    zeroIndex[index] = 1\n",
    "    zeroIndex= np.expand_dims(zeroIndex,axis=1)\n",
    "    value = nn.get_middle_layer(zeroIndex)\n",
    "    wordEmbeddingRelation[word] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let me get the matrices of all the words!!! \n",
    "\n",
    "values = np.array(list(wordEmbeddingRelation.values()))\n",
    "values = values.reshape(values.shape[0],values.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating PCA by myself! \n",
    "# you think I cannot do that? \n",
    "def get2DimVector(vectors):\n",
    "    values = np.array(list(wordEmbeddingRelation.values()))\n",
    "    words = list(wordEmbeddingRelation.keys())\n",
    "    \n",
    "    values = values.reshape((values.shape[0],values.shape[1]))\n",
    "    \n",
    "    eachColumnValues = np.array([vectors[:,i] for i in range(20)])\n",
    "    \n",
    "    values = []\n",
    "    \n",
    "    for eachColumnValue in eachColumnValues:\n",
    "        mean = np.mean(eachColumnValue)\n",
    "        std_dev= np.std(eachColumnValue)\n",
    "        values.append((eachColumnValue-mean)/std_dev)\n",
    "    \n",
    "    values = np.array(values)\n",
    "    \n",
    "    cov_mat = np.cov(values)\n",
    "    \n",
    "    eigen_vals, eigen_vecs = np.linalg.eig(cov_mat)\n",
    "    \n",
    "    eigen_pairs = [(np.abs(eigen_vals[i]), eigen_vecs[:, i]) for i in range(len(eigen_vals))]\n",
    "    \n",
    "    eigen_pairs.sort(key=lambda k: k[0], reverse=True)\n",
    "    \n",
    "    w = np.hstack((eigen_pairs[0][1][:, np.newaxis], eigen_pairs[1][1][:, np.newaxis]))\n",
    "    X_train = values.T.dot(w)\n",
    "    \n",
    "    return X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager as fm, rcParams\n",
    "\n",
    "fpath = os.path.join(rcParams[\"datapath\"], \"fonts/ttf/MangalRegular.ttf\")\n",
    "prop = fm.FontProperties(fname=fpath)\n",
    "\n",
    "\n",
    "X_train = get2DimVector(values)\n",
    "corelatedWords = list(wordEmbeddingRelation.keys())\n",
    "\n",
    "ValuesPrint = 10\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X_train[:ValuesPrint,0], X_train[:ValuesPrint,1],c='r')\n",
    "\n",
    "for i,txt in enumerate(X):\n",
    "    ax.annotate(u'{}'.format(corelatedWords[i]), (X_train[i,0], X_train[i,1]),fontproperties=prop)\n",
    "    if i==ValuesPrint:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
